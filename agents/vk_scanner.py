"""
VK Scanner Agent ‚Äî –ü–∞—Ä—Å–∏–Ω–≥ –ø—É–±–ª–∏—á–Ω—ã—Ö –≥—Ä—É–ø–ø VK
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç VK API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤

API –ö–ª—é—á: –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π, –Ω—É–∂–µ–Ω —Å–µ—Ä–≤–∏—Å–Ω—ã–π –∫–ª—é—á
–õ–∏–º–∏—Ç: 5 req/sec

–ö–ê–ö –ü–û–õ–£–ß–ò–¢–¨ –ö–õ–Æ–ß:
1. –ó–∞–π–¥–∏ –Ω–∞ https://vk.com/apps?act=manage
2. –°–æ–∑–¥–∞–π –Ω–æ–≤–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ (Standalone)
3. –ü–æ–ª—É—á–∏ "–°–µ—Ä–≤–∏—Å–Ω—ã–π –∫–ª—é—á –¥–æ—Å—Ç—É–ø–∞" –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
"""

import json
import urllib.request
import urllib.parse
import urllib.error
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional

from config import PAIN_KEYWORDS, BLACKLIST_KEYWORDS, FRESH_DIR, TODAY

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ API –∫–ª—é—á–∞ –∏–∑ config
try:
    from config import VK_SERVICE_KEY
except ImportError:
    VK_SERVICE_KEY = ""


# –°–ø–∏—Å–æ–∫ —É–∑–±–µ–∫–∏—Å—Ç–∞–Ω—Å–∫–∏—Ö VK –≥—Ä—É–ø–ø
VK_GROUPS = [
    "rabota_tashkent",       # –†–∞–±–æ—Ç–∞ –≤ –¢–∞—à–∫–µ–Ω—Ç–µ
    "it_uzbekistan",         # IT Uzbekistan
    "tashkent_city",         # –¢–∞—à–∫–µ–Ω—Ç
    "uzbekistan_news",       # –ù–æ–≤–æ—Å—Ç–∏ –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω–∞
    "business_uzbekistan",   # –ë–∏–∑–Ω–µ—Å –£–∑–±–µ–∫–∏—Å—Ç–∞–Ω
    "freelance_uz",          # –§—Ä–∏–ª–∞–Ω—Å –£–ó
    "study_abroad_uz",       # –£—á—ë–±–∞ –∑–∞ —Ä—É–±–µ–∂–æ–º
    "kuply_prodam_tashkent", # –ö—É–ø–ª—è-–ø—Ä–æ–¥–∞–∂–∞
]


class VKScanner:
    """
    –°–∫–∞–Ω–µ—Ä –ø—É–±–ª–∏—á–Ω—ã—Ö –≥—Ä—É–ø–ø VK.
    """
    
    API_URL = "https://api.vk.com/method"
    API_VERSION = "5.199"
    
    def __init__(self, access_token: str):
        """
        Args:
            access_token: –°–µ—Ä–≤–∏—Å–Ω—ã–π –∫–ª—é—á –¥–æ—Å—Ç—É–ø–∞ VK
        """
        self.access_token = access_token
    
    def _request(self, method: str, params: dict) -> Optional[dict]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ VK API"""
        params["access_token"] = self.access_token
        params["v"] = self.API_VERSION
        
        url = f"{self.API_URL}/{method}?{urllib.parse.urlencode(params)}"
        
        try:
            req = urllib.request.Request(url)
            with urllib.request.urlopen(req, timeout=10) as response:
                result = json.loads(response.read().decode("utf-8"))
                
                if "error" in result:
                    error = result["error"]
                    print(f"   ‚ö†Ô∏è VK Error: {error.get('error_msg', 'Unknown')}")
                    return None
                
                return result.get("response")
                
        except Exception as e:
            print(f"   ‚ùå Request error: {e}")
            return None
    
    def get_wall_posts(self, group_id: str, count: int = 30) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å—Ç—ã —Å–æ —Å—Ç–µ–Ω—ã –≥—Ä—É–ø–ø—ã.
        
        Args:
            group_id: ID –∏–ª–∏ short_name –≥—Ä—É–ø–ø—ã (–±–µ–∑ –º–∏–Ω—É—Å–∞)
            count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤
        """
        print(f"üì° Fetching VK: {group_id}")
        
        response = self._request("wall.get", {
            "domain": group_id,
            "count": min(count, 100),
            "filter": "all",
        })
        
        if not response:
            return []
        
        posts = []
        for item in response.get("items", []):
            posts.append({
                "id": item.get("id"),
                "text": item.get("text", "")[:500],
                "date": datetime.fromtimestamp(item.get("date", 0)).isoformat(),
                "likes": item.get("likes", {}).get("count", 0),
                "comments": item.get("comments", {}).get("count", 0),
                "views": item.get("views", {}).get("count", 0),
                "group": group_id,
            })
        
        print(f"   ‚úÖ Found {len(posts)} posts")
        return posts
    
    def search_posts(self, query: str, count: int = 50) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –ø–æ—Å—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤
        """
        print(f"üîç VK Search: '{query}'")
        
        response = self._request("newsfeed.search", {
            "q": query,
            "count": min(count, 200),
            "extended": 0,
        })
        
        if not response:
            return []
        
        posts = []
        for item in response.get("items", []):
            posts.append({
                "id": item.get("id"),
                "text": item.get("text", "")[:500],
                "date": datetime.fromtimestamp(item.get("date", 0)).isoformat(),
                "likes": item.get("likes", {}).get("count", 0),
                "owner_id": item.get("owner_id"),
            })
        
        print(f"   ‚úÖ Found {len(posts)} posts")
        return posts


def classify_post(text: str) -> Dict:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –ø–æ—Å—Ç"""
    text_lower = text.lower()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ blacklist
    for word in BLACKLIST_KEYWORDS:
        if word in text_lower:
            return {"type": "blocked", "score": 0, "keywords": []}
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –±–æ–ª–∏
    pain_score = 0
    matched_keywords = []
    
    for keyword in PAIN_KEYWORDS:
        if keyword in text_lower:
            pain_score += 1
            matched_keywords.append(keyword)
    
    if pain_score >= 2:
        return {"type": "pain", "score": pain_score, "keywords": matched_keywords}
    elif pain_score == 1:
        return {"type": "question", "score": pain_score, "keywords": matched_keywords}
    else:
        return {"type": "neutral", "score": 0, "keywords": []}


def extract_pains_from_posts(posts: List[Dict]) -> List[Dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–æ–ª–∏ –∏–∑ –ø–æ—Å—Ç–æ–≤ VK"""
    pains = []
    
    for post in posts:
        classification = classify_post(post.get("text", ""))
        
        if classification["type"] in ["pain", "question"]:
            pains.append({
                "text": post.get("text", "")[:300],
                "group": post.get("group", ""),
                "type": classification["type"],
                "score": classification["score"],
                "keywords": classification["keywords"],
                "likes": post.get("likes", 0),
                "views": post.get("views", 0),
            })
    
    return sorted(pains, key=lambda x: x["score"], reverse=True)


def get_mock_data() -> Dict:
    """Mock –¥–∞–Ω–Ω—ã–µ –∫–æ–≥–¥–∞ –Ω–µ—Ç API –∫–ª—é—á–∞"""
    import random
    
    mock_posts = [
        "–ò—â—É —Ä–∞–±–æ—Ç—É –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–º –≤ –¢–∞—à–∫–µ–Ω—Ç–µ, –æ–ø—ã—Ç 2 –≥–æ–¥–∞ Python",
        "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ —Ö–æ—Ä–æ—à–∏–µ –∫—É—Ä—Å—ã –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞",
        "–ì–¥–µ –∫—É–ø–∏—Ç—å iPhone –¥–µ—à–µ–≤–ª–µ –≤—Å–µ–≥–æ?",
        "–ü—Ä–æ–±–ª–µ–º–∞ —Å –æ–ø–ª–∞—Ç–æ–π —á–µ—Ä–µ–∑ Click, –ø–æ–º–æ–≥–∏—Ç–µ!",
        "–ò—â—É —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä–∞ –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ DTM",
        "–°–¥–∞—é –∫–≤–∞—Ä—Ç–∏—Ä—É –≤ —Ü–µ–Ω—Ç—Ä–µ –¢–∞—à–∫–µ–Ω—Ç–∞, 3 –∫–æ–º–Ω–∞—Ç—ã",
        "–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –≤–∏–∑—É –≤ –ö–æ—Ä–µ—é?",
        "–ù—É–∂–µ–Ω —Ö–æ—Ä–æ—à–∏–π —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥, –ø–æ—Å–æ–≤–µ—Ç—É–π—Ç–µ",
    ]
    
    posts = []
    for i, text in enumerate(mock_posts):
        posts.append({
            "id": i,
            "text": text,
            "date": datetime.now().isoformat(),
            "likes": random.randint(0, 50),
            "views": random.randint(100, 1000),
            "group": "mock_group",
        })
    
    pains = extract_pains_from_posts(posts)
    
    return {
        "date": TODAY,
        "api_mode": False,
        "groups_count": 0,
        "posts_count": len(posts),
        "pains_count": len(pains),
        "posts": posts,
        "pains": pains,
    }


def save_vk_data(data: Dict) -> Path:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ VK"""
    output_dir = FRESH_DIR / "vk"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_file = output_dir / f"uz_{TODAY}.json"
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ Saved VK data to {output_file}")
    return output_file


def run(use_api: bool = True):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–≥–µ–Ω—Ç–∞"""
    print("üí¨ VK Scanner Agent starting...")
    print(f"üìÖ Date: {TODAY}")
    print(f"üîë VK API Key: {'‚úÖ Configured' if VK_SERVICE_KEY else '‚ùå Not configured'}")
    
    if not VK_SERVICE_KEY or not use_api:
        print("‚ö†Ô∏è Using mock data (no API key)")
        data = get_mock_data()
        save_vk_data(data)
        return data
    
    scanner = VKScanner(VK_SERVICE_KEY)
    
    all_posts = []
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç—ã –∏–∑ –≥—Ä—É–ø–ø
    print("\nüîç Fetching posts from groups...")
    for group in VK_GROUPS[:5]:  # –õ–∏–º–∏—Ç 5 –≥—Ä—É–ø–ø
        posts = scanner.get_wall_posts(group)
        all_posts.extend(posts)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (5 req/sec)
        import time
        time.sleep(0.3)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–æ–ª–∏
    print("\nüíä Extracting pains...")
    pains = extract_pains_from_posts(all_posts)
    print(f"   Found {len(pains)} pains")
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    all_data = {
        "date": TODAY,
        "api_mode": True,
        "groups_count": len(VK_GROUPS),
        "posts_count": len(all_posts),
        "pains_count": len(pains),
        "posts": all_posts[:50],
        "pains": pains[:30],
    }
    
    print(f"\n{'='*50}")
    print(f"üìä Results:")
    print(f"   Groups: {len(VK_GROUPS)}")
    print(f"   Posts: {len(all_posts)}")
    print(f"   Pains: {len(pains)}")
    print(f"{'='*50}")
    
    save_vk_data(all_data)
    return all_data


if __name__ == "__main__":
    run(use_api=True)
