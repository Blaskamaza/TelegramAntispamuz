"""
Google Trends Agent â€” ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ² Ğ£Ğ·Ğ±ĞµĞºĞ¸ÑÑ‚Ğ°Ğ½Ğ°
Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ pytrends Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²

Ğ‘Ğ•Ğ¡ĞŸĞ›ĞĞ¢ĞĞ: ĞĞµÑ‚ ÑĞ²Ğ½Ñ‹Ñ… Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ¾Ğ² API
"""

import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional

from config import GOOGLE_TRENDS_KEYWORDS, PAIN_KEYWORDS, FRESH_DIR, TODAY

# PyTrends
try:
    from pytrends.request import TrendReq
    PYTRENDS_AVAILABLE = True
except ImportError:
    PYTRENDS_AVAILABLE = False
    print("âš ï¸ pytrends not installed. Run: pip install pytrends")


class GoogleTrendsScanner:
    """
    Ğ¡ĞºĞ°Ğ½ĞµÑ€ Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ² Google Ğ´Ğ»Ñ Ğ£Ğ·Ğ±ĞµĞºĞ¸ÑÑ‚Ğ°Ğ½Ğ°.
    """
    
    def __init__(self, geo: str = "UZ", hl: str = "ru"):
        """
        Args:
            geo: ĞšĞ¾Ğ´ ÑÑ‚Ñ€Ğ°Ğ½Ñ‹ (UZ = Ğ£Ğ·Ğ±ĞµĞºĞ¸ÑÑ‚Ğ°Ğ½)
            hl: Ğ¯Ğ·Ñ‹Ğº (ru = Ñ€ÑƒÑÑĞºĞ¸Ğ¹)
        """
        self.geo = geo
        self.hl = hl
        self.pytrends = None
        
        if PYTRENDS_AVAILABLE:
            self.pytrends = TrendReq(hl=hl, tz=300)  # UTC+5 Ğ´Ğ»Ñ Ğ£Ğ·Ğ±ĞµĞºĞ¸ÑÑ‚Ğ°Ğ½Ğ°
    
    def get_trending_searches(self) -> List[str]:
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ²Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ² ÑÑ‚Ñ€Ğ°Ğ½Ğµ.
        
        Returns:
            Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
        """
        if not self.pytrends:
            return self._mock_trending()
        
        try:
            # Ğ”Ğ½ĞµĞ²Ğ½Ñ‹Ğµ Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ (trending searches)
            trending_df = self.pytrends.trending_searches(pn='uzbekistan')
            if trending_df is not None and not trending_df.empty:
                return trending_df[0].tolist()[:20]
        except Exception as e:
            print(f"âš ï¸ Trending searches error: {e}")
        
        # Fallback: realtime trends
        try:
            realtime = self.pytrends.realtime_trending_searches(pn='UZ')
            if realtime is not None and not realtime.empty:
                return realtime['title'].tolist()[:20]
        except Exception as e:
            print(f"âš ï¸ Realtime trends error: {e}")
        
        return self._mock_trending()
    
    def get_interest_over_time(self, keywords: List[str], timeframe: str = "today 3-m") -> Dict:
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºÑƒ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ° Ğº ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼.
        
        Args:
            keywords: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ² (Ğ¼Ğ°ĞºÑ 5)
            timeframe: ĞŸĞµÑ€Ğ¸Ğ¾Ğ´ (today 3-m = 3 Ğ¼ĞµÑÑÑ†Ğ°)
        
        Returns:
            Dict Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ°
        """
        if not self.pytrends or not keywords:
            return {}
        
        try:
            # Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 5 ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ²
            kw_list = keywords[:5]
            
            self.pytrends.build_payload(
                kw_list, 
                cat=0, 
                timeframe=timeframe, 
                geo=self.geo
            )
            
            interest_df = self.pytrends.interest_over_time()
            
            if interest_df is not None and not interest_df.empty:
                # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ² dict
                result = {}
                for kw in kw_list:
                    if kw in interest_df.columns:
                        result[kw] = {
                            "avg": float(interest_df[kw].mean()),
                            "max": int(interest_df[kw].max()),
                            "trend": "rising" if interest_df[kw].iloc[-1] > interest_df[kw].iloc[0] else "falling"
                        }
                return result
                
        except Exception as e:
            print(f"âš ï¸ Interest over time error: {e}")
        
        return {}
    
    def get_related_topics(self, keyword: str) -> Dict:
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚ĞµĞ¼Ñ‹ Ğ´Ğ»Ñ ĞºĞ»ÑÑ‡ĞµĞ²Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°.
        
        Returns:
            Dict Ñ rising Ğ¸ top Ñ‚ĞµĞ¼Ğ°Ğ¼Ğ¸
        """
        if not self.pytrends:
            return {}
        
        try:
            self.pytrends.build_payload([keyword], geo=self.geo)
            related = self.pytrends.related_topics()
            
            result = {"rising": [], "top": []}
            
            if keyword in related:
                data = related[keyword]
                
                if 'rising' in data and data['rising'] is not None:
                    result["rising"] = data['rising']['topic_title'].tolist()[:10]
                    
                if 'top' in data and data['top'] is not None:
                    result["top"] = data['top']['topic_title'].tolist()[:10]
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ Related topics error: {e}")
            return {}
    
    def get_related_queries(self, keyword: str) -> Dict:
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ ĞºĞ»ÑÑ‡ĞµĞ²Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°.
        """
        if not self.pytrends:
            return {}
        
        try:
            self.pytrends.build_payload([keyword], geo=self.geo)
            related = self.pytrends.related_queries()
            
            result = {"rising": [], "top": []}
            
            if keyword in related:
                data = related[keyword]
                
                if 'rising' in data and data['rising'] is not None:
                    result["rising"] = data['rising']['query'].tolist()[:10]
                    
                if 'top' in data and data['top'] is not None:
                    result["top"] = data['top']['query'].tolist()[:10]
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ Related queries error: {e}")
            return {}
    
    def _mock_trending(self) -> List[str]:
        """Mock Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
        return [
            "Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° Ğ² Ñ‚Ğ°ÑˆĞºĞµĞ½Ñ‚Ğµ",
            "ĞºÑƒÑ€Ñ Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€Ğ° ÑƒĞ·Ğ±ĞµĞºĞ¸ÑÑ‚Ğ°Ğ½",
            "DTM 2026 Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹",
            "iPhone Ñ†ĞµĞ½Ğ° Ğ£Ğ·Ğ±ĞµĞºĞ¸ÑÑ‚Ğ°Ğ½",
            "Ñ„Ñ€Ğ¸Ğ»Ğ°Ğ½Ñ Ğ´Ğ»Ñ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ÑÑ‰Ğ¸Ñ…",
            "Ğ±Ğ¸Ğ·Ğ½ĞµÑ Ğ¸Ğ´ĞµĞ¸ 2026",
            "IT ĞºÑƒÑ€ÑÑ‹ Ñ‚Ğ°ÑˆĞºĞµĞ½Ñ‚",
            "ĞºĞ²Ğ°Ñ€Ñ‚Ğ¸Ñ€Ğ° Ğ°Ñ€ĞµĞ½Ğ´Ğ° Ñ‚Ğ°ÑˆĞºĞµĞ½Ñ‚",
            "ĞºÑ€ĞµĞ´Ğ¸Ñ‚ Ğ±ĞµĞ· Ğ¾Ñ‚ĞºĞ°Ğ·Ğ°",
            "Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº ĞºÑƒÑ€ÑÑ‹",
        ]


def extract_pains_from_trends(trends: List[str], keywords: List[str]) -> List[Dict]:
    """
    Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ±Ğ¾Ğ»Ğ¸ Ğ¸Ğ· Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ².
    
    Args:
        trends: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
        keywords: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ±Ğ¾Ğ»ĞµĞ²Ñ‹Ñ… ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ²
    
    Returns:
        Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ±Ğ¾Ğ»ĞµĞ¹
    """
    pains = []
    
    for trend in trends:
        trend_lower = trend.lower()
        matched_keywords = []
        
        for kw in keywords:
            if kw in trend_lower:
                matched_keywords.append(kw)
        
        if matched_keywords:
            pains.append({
                "text": trend,
                "type": "trend",
                "keywords": matched_keywords,
                "score": len(matched_keywords),
            })
    
    return sorted(pains, key=lambda x: x["score"], reverse=True)


def save_trends_data(data: Dict) -> Path:
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ²"""
    output_dir = FRESH_DIR / "trends"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_file = output_dir / f"uz_{TODAY}.json"
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Saved trends data to {output_file}")
    return output_file


def run():
    """ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"""
    print("ğŸ“ˆ Google Trends Agent starting...")
    print(f"ğŸ“… Date: {TODAY}")
    print(f"ğŸŒ Region: UZ (Uzbekistan)")
    print(f"ğŸ”‘ PyTrends: {'âœ…' if PYTRENDS_AVAILABLE else 'âŒ Mock'}")
    
    scanner = GoogleTrendsScanner(geo="UZ", hl="ru")
    
    # 1. Ğ¢Ñ€ĞµĞ½Ğ´Ğ¾Ğ²Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹
    print("\nğŸ” Getting trending searches...")
    trending = scanner.get_trending_searches()
    print(f"   Found {len(trending)} trends")
    
    # 2. Ğ˜Ğ½Ñ‚ĞµÑ€ĞµÑ Ğº ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼
    print("\nğŸ“Š Analyzing interest over time...")
    interest = scanner.get_interest_over_time(GOOGLE_TRENDS_KEYWORDS[:5])
    for kw, data in interest.items():
        print(f"   {kw}: avg={data.get('avg', 0):.1f}, trend={data.get('trend', 'n/a')}")
    
    # 3. Ğ¡Ğ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ Ñ‚Ğ¾Ğ¿ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ²
    print("\nğŸ”— Getting related queries...")
    related = {}
    for kw in GOOGLE_TRENDS_KEYWORDS[:3]:  # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 3 Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸
        related[kw] = scanner.get_related_queries(kw)
        if related[kw].get("rising"):
            print(f"   {kw}: {len(related[kw]['rising'])} rising queries")
    
    # 4. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ĞµĞ¹
    print("\nğŸ’Š Extracting pains from trends...")
    pains = extract_pains_from_trends(trending, PAIN_KEYWORDS)
    print(f"   Found {len(pains)} pains")
    
    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
    all_data = {
        "date": TODAY,
        "region": "UZ",
        "trending_searches": trending,
        "interest_over_time": interest,
        "related_queries": related,
        "pains_found": len(pains),
        "pains": pains,
    }
    
    print(f"\n{'='*50}")
    print(f"ğŸ“Š Results:")
    print(f"   Trending: {len(trending)}")
    print(f"   Keywords analyzed: {len(interest)}")
    print(f"   Pains found: {len(pains)}")
    print(f"{'='*50}")
    
    save_trends_data(all_data)
    return all_data


if __name__ == "__main__":
    run()
